Terminal commands:
	Local
		dev_appserver.py .
		open http://localhost:8080
	Deploy
		appcfg.py update .
			User: ypodeswa@gmail.com
			Paswword: my Google pass (see LP, it's not a common one)
		open http://hello-udacity-yasha.appspot.com
	Backup
		cp app.yaml main.py index.yaml past_versions/2_PS3_blog/
		cp -r templates/ past_versions/2_PS3_blog/templates/
		cp -r static/ past_versions/2_PS3_blog/static/

#####################################
# Lesson 1: How the Web Works
#####################################

We'll cover
	- the web (what is it)
	- HTML (main doc type of the web)
	- URLs (how to refer to docs)
	- HTTP (protocol that the web runs on)
	- web applications

The World Wide Web
	- a collection of HTML docs
	- HTML
		- HyperText Markup Language
		- links btwn HTML = Hyper Links
	- Note that we can find many files other than HTML
		- plain text, images, pdfs, videos, etc.
	- Major pieces of the web
			1) You (your computer + browser)
				- browser = a program that displays files found on the web
				- all browsers are a bit different, none are "perfect"
				- must always keep in mind that all browsers behave differently
			2) The Internet
				- the world's largest computer network
			3) HTTP
				- the main protocol of the web
			3) Servers
				- computers that host the files that make up the web
	- So how does this all work?
		- You make requests via the internet to servers, using the HTTP protocol
		- Servers are computers optimized for sitting in a closet, hosting files

HTML basics
	- made up of:
		- text content
			- "what you see"
			- if you just enter text with zero markup, it will simpply show up as plain text
		- markup
			- "what it looks like"
			- Elements:
				<NAME>Contents</NAME>
			- tags can be nested
		- references to
			- "i.e. images and videos"
		- links to other pages
	- Example tabs:
		- bold tag
			<b>Makes stuff bold</b>
		- emphasis tag
			<em>Makes stuff italic</em>
		- anchor tag
			<a href="www.reddit.com">derp</a>
		- images tag
			<img src="url" alt="text">
				- note the two attributes, src and alt
				- definitely nice to include alt, good for broken pages and blind people
				- image tags are VOID tags
					- they have no content, so they don't need a closing tag
				- note that images just appear in line with text
	- What happens when we forget to close tags?
		- say it's an <em> tag, everything after will be italicized
		- depends on the tag/browser, though
	- Whitespace
		- in HTML all whitespace (tabs, single spaces, multiple spaces, new lines) turn into single spaces
		- BY DEFAULT, ANY AMOUNT OF WHITESPACE TURNS INTO A SINGLE SPACE
		- for example:
			this text is really
			too long for one line
		- displays as:
			this text is really too long for one line
		- if we want a new line
			this text is really
			<br>
			too long for one line
		- or a blank line between
			this text is really
			<br>
			<br>
			too long for one line
	- Other ways of doing new lines
		- paragraph tag
			<p>this text is really</p>
			<p>too long for onw linw</p>
	- Inline vs. block
		- the <br> tag is inline
			- it just ends a line
			- examples: <b>, <em>, <img>, <span>
		- the <p> tag is block
			- it creates an invisible box, with things lke a 
			- examples: <p>, <div>
		- <span> and <div> are basically inline and block versions of the same thing
			- they just contain text, but don't do anything else

HTML documents
	- Example of basic structure:
<!doctype html>
<html>
<head>
	<title>Title!</title>
</head>
<body>
	<b>content</b>
</body>
</html>

		- head contains meta-data, title, JavaScript, CSS, etc.
			- also contains the doctype
		- body contains the actual contents of the document
			- for most of this course we'll be working on generating the contents of the body tags

URLs
	- Uniform Resource Locator
	- Example:
			http://www.udacity.com/
				Protocol: http
					- could also be something like ftp
				Host: www.udacity.com
					- domain name of server that has the doc we want to fetch
					- can also just be an IP address
				Path: /
	- Query parameters
		- also called GET parameters
		- example:
			http://example.com/foo?P=1&q=neat
				- First parameter is after the ?, subsequent parameters are after the &
					- so in this case parameter P is "1", parameter q is "neat"
				- when you make a request to the server for said path, you ALSO pass this extra info
					- all sorts of handy uses for this!
	- Fragments
		- represented with a # sign
		- examples:
			http://www.example.com/foo#fragment
			http://www.example.com/foo?p=1#fragment
		- note that fragments come after query params
		- fragments ARE NOT SENT TO THE SERVER, just used on the local machine
	- Ports
		- to connect to a machine, you need the host AND the port
		- by default the port = 80, so:
			http://www.example.com/
			- Is really
			http://www.example.com:80/
		- You can also explicitly specify the port
			http://localhost:8000/
	- Final example of structure:
		http://example.com:80/toys?p=foo#blah
	- There are other parts to a url, but we won't cover them now

HTTP Requests
	- HTTP
			-HyperText Transfer Protocol
			- the main protocol of the web
				- what our browser uses to talk to web servers
	- For example, when we type:
		htttp://www.example.com/foo
		- We send this request line
		GET /foo HTTP/1.1
			- GET is the method
				- most often used for getting docs from the server
				- another popular method is POST
					- most often used for posting data to the server
			- /foo is the path
				- the actual document we're requesting
			- HTTP/1.1 is the version
				- most browser speak 1.1, but 1.0 still has a few uses
			- Note that there's no host name
				- Our browser already connected to the host
					- www.example.com was used to make this connection
				- it's just the /foo part that's making the request
	- More complex example:
		- URL
			http://www.example.com/foo/logo.png?p=1#tricky
		- GET request:
			GET /foo/logo.png?p=1 HTTP/1.1
		- Note that the path...
			- INCLUDES the query parameters
			- DOESN'T INCLUDE fragments
	- The request line is followed by a number of headers, for example:
		GET /foo?p=1 HTTP/1.1
		Host: www.example.com
		User-Agent: chrome
		- We're already connected to the server, why do we need the host?
			- Because one server can host multiple websites!
		- User-Agent is generally your browser
			- if one IP and one fake user agent is just pumelling your site, they're probably malicious
	- Valid Headers:
			Host: www.hipmunk.com
			User-Agent: Chrome
			i-made-this-up: whatever
	- Invalid headers
			User Agent: Chrome
			Host www.hipmunk.com
	- HEADERS NAMES MUST BE ALL ONE WORD, AND MUST BE FOLLOWED BY A ": "

HTTP Responses
	- Browser makes a request, server responds with a response
	- Returns docs plus...
	- Basic HTTP response:
		- Request:
			- Request line:
				GET /foo HTTP/1.1
		- Response:
			- Status line (alagous to request line):
				HTTP/1.1 200 OK
					- version status-code reason-phrase
					- Common status codes:
						- 200 OK
							- "Document was found"
							- the most common status code on the internet
						- 302 Found
							- "Document is located somewhere else"
						- 404 Not Found
							- "Document was not found"
						- 500 Server Error
							- Server broke trying to handle your request
		- Status codes start with a 1, 2, 3, 4 or 5
			- 2 = success
			- 3 = need to do something different to find this doc
			- 4 = error on the browser side (trying to request a doc that doesn't exist)
			- 5 = error on the server side
	- Status line is followed by headers
		- Example:
				HTTP/1.1 200 OK
				Date: Tue Mar 2012 04:33:33 GMT
				Server: Apache/2.2.3
				Content-Type: text/html;
				Content-Length: 1539
		- Some headers are required, some are not
			- Date is always there
			- You may not want to include the server, or to make something up
				- Why display vulnerabilities to a hacker?
			- Content type is always there
			- Content length is somewhat optional

Playing around with HTTP requests
	- Open terminal, enter:

telnet www.yashley2014.com 80

	- This is what your browser is sending when you enter the URL www.yashley2014.com (it's going to port 80)
	- Returns:

Trying 74.125.28.147...
Connected to http://www.yashley2014.com.
Escape character is '^]'.

	- Then we can include the GET request

GET / HTTP/1.0
Host: www.yashley2014.com

	- Why HTTP 1.0 and not 1.1?
		 - The default behaviour in 1.1 is to not close the connection once it's finished, which is annoying for testing
	- Returns:

HTTP/1.1 200 OK
Server: nginx/1.4.3
Date: Sun, 05 Jan 2014 01:11:31 GMT
Content-Type: text/html
Content-Length: 3110
Last-Modified: Mon, 04 Nov 2013 03:51:03 GMT
Connection: close
ETag: "527719a7-c26"
Accept-Ranges: bytes

<!DOCTYPE html>
<!-- saved from url=(0043)http://getbootstrap.com/examples/jumbotron/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
etc. (more HTML code)

	- So we see the HTTP response there at the top!
		- the status line, and a whole bunch of headers

	- What if you get a 302 error?
		- it should return a "Location" header
			- this should tell you where the document is actually located (a new URL)
		- if you do a GET request for this new URL, you *SHOULD* get a 200 response, with your doc


Servers
	- Purpose: to respond to HTTP requests
	- 2 main types of responses from servers
		1) Static
			- server returns a pre-written file
				- e.g. an image
		2) Dynamic
			- response built on the fly by the program that's running on the server
			- most sites now are built dynamically, on the fly, by web applications
	- So a web application lives on a server, gets HTTP requests, and generates documents to return to clients


#####################################
# Problem Set 1 - Creating Your First Site
#####################################

Directions:
	- Install Google App Engine (the Pythin version)
	- Put online a basic app that says "Hello, Udacity!"
	- Submit the URL to Udacity

Basically just follow directions on this page:
https://developers.google.com/appengine/?csw=1#getstarted-framework-flask

My local copy is at:
/Users/yasha.podeswa/Documents/everything_else/git_repos/appengine-django-skeleton

/usr/local/google_appengine points to the SDK, so add this to my path

Open the Google app engine app, create a new project
Mine is called "hello-udacity-yasha"
And it's located at:
/Users/yasha.podeswa/Documents/everything_else/git_repos/hello-udacity-yasha

Edit main.py so the argument here is 'Hello Udacity!'
class MainHandler(webapp2.RequestHandler):
    def get(self):
        self.response.write('Hello Udacity!')

Make the app in the online app engine console as well

Deploy with the local app engine program

Go to:
http://hello-udacity-yasha.appspot.com/

To see it deployed

Or, to run it locally:

Through the GUI, simply click run

Or, through terminal

cd to the app
dev_appserver.py .

. is for current directory, or you can type the directory

Then visit at localhost:8080

And to deploy online:

appcfg.py update .

User: ypodeswa@gmail.com
Paswword: mypass

Or just use deploy in the GUI

Again, to see it deployed, go to:
http://hello-udacity-yasha.appspot.com/


#####################################
# Office Hours 1
#####################################

Questions and Answers:

- Why Google App Engine?
	- Easiest way to get something up an running
- What is Google App Enginge
	- You just write Python code
	- You use the console or launcher to upload your app
- What are some useful things to know about front end app development?
	- Need to know HTML, CSS, JS
- Is Google App Engine a good solution for large scale projects?
	- Many people do use it in production
	- But it can get a bit expensive
	- ALSO, when we start doing things like user registration and cookies, we'll be looking at it from a general overall sense


#####################################
# Lesson 2
#####################################

Forms
	- We'll be working with the file "play.html"
	- See <form> tag in play.html

<form>
	<input name="q">
</form>

	- What happens when a user types "hello", then hits enter on the form?
	- the url changes to: play.html?q=hello

	- Let's add a submit button:

<form>
	<input name="q">
	<input type="submit">
</form>

	- creates a submit button, which is no different to submitting with enter

	- Ok, so now the form just submits to itself, which kind of sucks
	- How do we make it submit elsewhere?
		- With the "action" attribute

<form action="/foo">
	<input name="q">
	<input type="submit">
</form>

	- the action tag contains the URL where we should search to
	- for example:

<form action="http://www.google.com/search">
	<input name="q">
	<input type="submit">
</form>

	- Now queries are submitted to Google search results, and our browser re-directs there!
		- Why did this work?
			- We generated code that sent us to:
				http://www.google.com/search?q=what+we+searched
			- This is the same syntax Google search uses!
	- Why the "pluses"?
		- URLs can't have spaces in them
		- Browser did "URL encoding"
			- turns spaces into pluses
		- There are other escape characters, i.e.
			- many browsers turn ! into %21, for example

###########
Live web applications
###########

	- Let's start with the simple hello world Python example that Google has on the app engine

import webapp2

class MainHandler(webapp2.RequestHandler):
	def get(self):
		self.response.headers['Content-Type'] = 'text/plain'
		self.response.write('Hello, Udacity!')

app = webapp2.WSGIApplication([('/', MainHandler)], debug=True)

The "app = " line is the URL mapping section
	- there's one URL, "/", and it maps to the handler "MainHandler"
	- The class has a function called "get", which takes a parameter called "self" (a common parameter to many Python methods)
		- get does two things:
			1) It takes self.response, the global response object that this framework uses.  Then it sets a header, where the "Content-Type" is set to "text/plain".  By default this is set to "text/html"
			2) Then it writes the string "Hello, Udacity!"

What if we want something more interesting?  Let's replace the string with a variable that holds a string:

import webapp2

form = """
<form action="http://www.google.com/search">
	<input name="q">
	<input type="submit">
</form>
"""

class MainHandler(webapp2.RequestHandler):
	def get(self):
		self.response.headers['Content-Type'] = 'text/plain'
		self.response.write(form)

app = webapp2.WSGIApplication([('/', MainHandler)], debug=True)

But this only returns text showing the HTML, not the rendered HTML!
	- Why?  Because of the "text/html" header!
	- Comment out that line to render properly

Now lets make it submit to the server, not to Google!
	- Change the form's attribute:

<form action="/testform">

	- And also we need our app to be able to handle more than just '/'

class TestHandler(webapp2.RequestHandler):
	def get(self):
		q = self.request.get("q")
		self.response.out.write(q)

app = webapp2.WSGIApplication([('/', MainHandler),
	('/testform', TestHandler)],
	debug=True)

	- Note how we added the URL mapping for '/testform', and had it handled by TestHandler
	- BUT we had to create the TestHandler class!
		- This class:
			- Sets a variable called q, that comes from self.request
				- response is an object representing the response we'll send to the client
				- request is an object representing the request we'll get from the client
					- we can call get on it to get different parameters (in this case we're 'getting' the parameter q)
			- returns q
				- So the response will now display this variable
				- So now when we submit "hello", it will just return a page saying "hello", at the URL http://localhost:8080/testform?q=hello

- What if we change TestHandler to this, then submit?

class TestHandler(webapp2.RequestHandler):
	def get(self):
		# q = self.request.get("q")
		# self.response.out.write(q)
		self.response.headers['Content-Type'] = 'text/plain'
		self.response.out.write(self.request)

- We see the HTTP request!
GET /testform?q=hello+world HTTP/1.1
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Language: en-US,en;q=0.8
Host: localhost:8080
Referer: http://localhost:8080/
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.63 Safari/537.36
X-Appengine-Country: ZZ

- There's the request line, then a bunch of headers
	- The Referer header is interesting, it tells you the URL that sent the request
		- Also, Referer is misspelled :)  Happened once, kept that way for backwards compatibility
- Note that if we hadn't set the content type to text/plain, it would have looked weird
- We printed out the Python object self.request
	- This object prints to look exactly like an HTTP request

The above is a very handy debugging tool!


Ok, let's add a new method to our form, "post"
	- We do this in the HTML:

form = """
<form method="post" action="/testform">
	<input name="q">
	<input type="submit">
</form>
"""

	- the default for forms method is "get"
		- but here we can specify a different method for what will happen when you submit
	- What will happen if we submit now?
		- We get the following error message
"""405 Method Not Allowed
The method POST is not allowed for this resource."""

- Remember, 405 is the status code
	- status codes starting with 4 are errors on the browser side
	- this one means "method not allowed"
- What's wrong?
	- The handler class for /testform is TestHandler
	- This class does not have a method defining what to do with get methods
		- let's add one:

class TestHandler(webapp2.RequestHandler):
	def get(self):
		q = self.request.get("q")
		self.response.out.write(q)
	def post(self):
		q = self.request.get("q")
		self.response.out.write(q)
		# self.response.headers['Content-Type'] = 'text/plain'
		# self.response.out.write(self.request)

- Now it once again just takes us to a new page displaying our query
	- However, the URL is different!
		- instead of:
			localhost:8080/testform?q=hello
		- it's
			localhost:8080/testform
		- there's no query part!
	- How do we see what happened?

class TestHandler(webapp2.RequestHandler):
	def get(self):
		q = self.request.get("q")
		self.response.out.write(q)
	def post(self):
		# q = self.request.get("q")
		# self.response.out.write(q)
		self.response.headers['Content-Type'] = 'text/plain'
		self.response.out.write(self.request)

- And this is what we see:

POST /testform HTTP/1.1
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Language: en-US,en;q=0.8
Cache-Control: max-age=0
Content-Length: 7
Content-Type: application/x-www-form-urlencoded
Content_Length: 7
Content_Type: application/x-www-form-urlencoded
Host: localhost:8080
Origin: http://localhost:8080
Referer: http://localhost:8080/
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.63 Safari/537.36
X-Appengine-Country: ZZ

q=dfhhh

- So the query has been passes in the HTML request
	- after the HTTP request headers, but still part of the request
	- note also that it's a POST request, not a GET request
- Also note that some headers are printed twice
	- we're not printing the actual request, we're printing the Python representation of the request
	- it's a little glitchy

- GET vs. POST:
	- GET
		- parameters in URL
		- used for fetching documents
		- maximum URL length
		- OK to cache
			- there are lots of machines btwn you and the server
			- caching along the way saves effort
				- You can turn this off with headers, but it's generally good
		- shouldn't change the server
		- OVERALL:
			- GET requests = simple requests for fetching files
			- GET parameters should be used to describe what files to fetch
	- POST
		- parameters in body
		- used for updating data
		- no max URL length (though servers can be configured to have a max length, often a few MB)
		- not OK to cache
			- the data in them is potentially sensitive
		- OK/meant to change the server
			- POST requests are for updating the server
			- POST requests are generally destructive in nature

- What if you don't use these requests as you should?
	- Case study: Base Camp, back in the day
		- you used to see a page with task, and a bunch of "Delete" options beside them
			- clicking delete would remove the item
		- the delete options were HTML links
			- automatically GET requests!
			- POST is for forms, not links
		- There was also another program, Google web accelerator
			- This was a browser extension
			- It would pre-load all links, so they're "ready to go" when you click on them
				- It would pre-load the delete links, and delete all your items!
	- So really these "delete" buttons should have been forms, not links

- Back to playing around with static html
	- simple form

<form>
	<input type="text" name="q">
	<input type="submit">
</form>

- Submit "some junk", will load the same page with the following URL:
file://localhost/Users/yasha.podeswa/Documents/everything_else/git_repos/coding_notes/Udacity/Web_Development_Course/play.html?q=some+junk

- So just adds the query parameter to the URL
	- the type="text" attribute is optional, it's the default
- Let's try other types!
	- type="password"
	- the URL is the same, but text typed in the in input appears as documents
- Key takeway:
	- the password is not sent securely to the server here, it's sent like any other parameter

- type="checkbox"
	- adds ?q=on if the box is checked when you hit submit
	- else simply adds ?
		- the q parameter doesn't appear at all
	- however, not all browsers behave the same
		- best practice when writing server side scripts:
			- treat q=on as checked
			- treat ANYTHING ELSE as off, just in case
	- what if there are a few checkboxes?

<form>
	<input type="checkbox" name="q">
	<input type="checkbox" name="r">
	<input type="checkbox" name="s">
	<br>
	<input type="submit">
</form>

- If you check the first two, the query section (after the ?) of the URL will be:
q=on&r=on

- Note how the parameters are separated by "&"

- type="radio"
	- by default, identical to checkboxes, EXCEPT they can't be unchecked
		- NOT how you'd expect them to perform!
		- how to make them perform as a group, so that only one can be selected at a time?
			- give them all the same name!

<form>
	<input type="radio" name="q">
	<input type="radio" name="q">
	<input type="radio" name="q">
	<br>
	<input type="submit">
</form>

- This makes sense, as only one can be on, no need for multiple names
	- BUT no matter which button you select, q=on
	- How do we know what button was selected?
		- the value parameter!

<form>
	<input type="radio" name="q" value="one">
	<input type="radio" name="q" value="two">
	<input type="radio" name="q" value="three">
	<br>
	<input type="submit">
</form>

- Click the second, submit, and:
q=two
- So it changes the value of the query parameter!

- Ok, so right now we have 3 annonymous radio buttons
	- How do we let the user know what they're clicking on?

<form>
	<label>
		One
		<input type="radio" name="q" value="one">
	</label>

	<label>
		Two
		<input type="radio" name="q" value="two">
	</label>

	<label>
		Three
		<input type="radio" name="q" value="three">
	</label>

	<br>
	<input type="submit">
</form>

- Will add labels in front of the radio buttons

- Lastly, let's look at how to do dropdown form elements:

<form>
	<select name="q">
		<option>one</option>
		<option>two</option>
		<option>three</option>
	</select>

	<br>
	<input type="submit">
</form>

- will give a dropdown
	- selecting the third item and hitting submit will give you:
q=three

- note how it's just the contents of the option tag
	- what if you want a different param passed?
		- use the value parameter!

<form>
	<select name="q">
		<option value="1">one</option>
		<option value="2">two</option>
		<option value="3">three</option>
	</select>

	<br>
	<input type="submit">
</form>

- will return:
q=1


#########
Validation
#########

- Idea - verify on the server side that we received what we expected to received
	- i.e. you're sending q=on
		- that's fine, server knows what to do
	- but what if you send q=broken, and our server doesn't know what to do with it?
		- even if the checkbox can't send this, it doesn't mean that users can't send arbitrary junk to our servers through other means
- Basically, your server can receive junk, and your server needs to know how to deal with it


- Example: back to the live web app
	- I'm not going to take notes on everything, just copy the code
	- Inspect the code to see what happens

- Quiz:
# Write a function valid_month() to verify 
# whether the data a user enters is a valid 
# month. If the passed in parameter 'month' 
# is not a valid month, return nothing. 
# If 'month' is a valid month, then return 
# the name of the month with the first letter 
# capitalized.

months = ['January',
	'February',
	'March',
	'April',
	'May',
	'June',
	'July',
	'August',
	'September',
	'October',
	'November',
	'December']

month_abbvs = dict((m[:3].lower(), m) for m in months)
# What this says is:
#   - we're creating a new dictionary
#   - for m in month (i.e. it will be 'January', then 'February', etc.)
#   - we'll create a dictionary where the keys are a substrings of the first 3 characters, to lower
#   - and the values are the original strings
# print month_abbvs

# If we weren't using the abbreviations:
# def valid_month(month):
# 	if month:
# 		cap_month = month.capitalize()
# 		if cap_month in months:
# 			return cap_month

# Using the abbvs:
def valid_month(month):
	if month:
		short_month = month[:3].lower()
		return month_abbvs.get(short_month)
# The get method of a Python dictionary first checks if the key is in the dict
#   - if it is, it'll return the value

print valid_month('JAN')					# January
print valid_month('JANuary')			# January
print valid_month('Jannnnnnnny')	# January
print valid_month('blah')					# None


# Ok, now let's do the same for days
# My solution:
def valid_day(day):
	if day:
		try:
			day_num = int(day)
		except ValueError:
			day_num = None
		if day_num:
			if day_num >= 1 and day_num <= 31:
				return day_num

# Their solution
def valid_day(day):
	if day and day.isdigit():
		day = int(day)
		if day > 0 and day <= 31:
			return day

# However, I think their solution will only work if passed strings
#  - .isdigit() is a method for strings
#  - if passed a number, you got problems

# Now to test for a valid year, which we'll say is between 1900 and 2020

def valid_year(year):
	if year and year.isdigit():
		year = int(year)
		if year > 1900 and year < 2020:
			return year

- How will these functions fit in?
	1) User makes GET request for the form
	2) Server responds with form data
	3) User makes POST request with the data
	4) Server runs valudation function
		- if data is good, server says thanks
		- if data is bad, re-send form data + error message

- So 3 things we have to do:
	1) Verify the user's input
	2) On error, render form again
	3) Include error message

# String substitution in Python
a = "hello"
print("<b> %s </b>" % a)
# prints: <b> hello </b>

# Another example:
t1 = "I think %s is a perfectly normal thing to do in public."
def sub1(s):
	return t1 % s
print sub1("running") 
# => "I think running is a perfectly normal thing to do in public."    

# Or to substitute multiple strings
t2 = "I think %s and %s are perfectly normal things to do in public."
def sub2(s1, s2):
	return t2 % (s1, s2)
print sub2("running", "sleeping") 
# => "I think running and sleeping are perfectly normal things to do in public."

# Finally, even more complex
#		Instead of stacking tonnes of %s, then %(s1, s2, s3, etc.)
#		We can use names and dictionaries
"test %(NAME)s text" % {"NAME": value}
# The name can appear in the string multiple times, and we can have multiple names

# Example
t3 = "I'm %(nickname)s. My real name is %(name)s, but my friends call me %(nickname)s."
def sub_m(name, nickname):
	return t3 % {"name": name, "nickname": nickname} 
print sub_m("Mike", "Goose") 
# => "I'm Goose. My real name is Mike, but my friends call me Goose."

# Ok, so we've integrated the above
# 	We now have a form that's showing an error message when you input the wrong data
# 	But it would be nice to keep the correct data!
# Let's look at default values:
<input type="text" value="cool">

# So for perserving a correct month, we'd do something like:
<input type="text" name="month" value="%(month)s">

- What about weird input?
	- For example, say someone enters foo">derp as the month
	- We'll be substituting this into the input tag's value attribute
		- So we'll get:
		<input value="foo">derp">
		- the string will be cut off, and it will be followed by derp">
			- Not what we want!
		- And what if instead of derp, they put in some malicious shit!

- How to fix this?  Escaping!
	- instead of returning ", we return &quot;
	- also:
		>		&gt;
		<		&lt;
		&		&amp;

- My escape html function:
def escape_html(s):
	terms = {
		">": "&gt;",
		"<": "&lt;",
		'"': "&quot;",
		"&": "&amp;"
	}
	l = list(s)
	output = []
	for c in l:
		if c in terms:
			output.append(terms[c])
		else:
			output.append(c)
	return "".join(output)

- Their solution:
def escape_html(s):
	for (i, o) in (("&", "&amp;"),
									(">", "&gt;"),
									("<", "&lt;"),
									('"', "&quot;")):
		s = s.replace(i, o)
	return s

- Or even simpler
import cgi
def escape_html(s):
	return cgi.escape(s, quote = True)


- Redirection
	- OK, so up to now our "success" doesn't send you to a new page
		- This is annoying because you can't share the link
		- You also can't refresh without an annoying message
	- Instead of returning the success HTML, we should return a redirect!
		- The server sends the redirect, then when we hit the new page we send a GET request, then we get the success HTML

- Optimal form behaviour
	- Keep re-serving the form until the user enters valid info
	- Once you get valid input, redirect them to a success page

- What we need to do:
	- make a "thanks" handler
	- add the /thanks URL
	- redirect to the /thanks URL

- In this case:
	- the post method of the main handler will redirect to /thanks when it gets valid data
	- the thanks handler will write our success message when it gets a GET request
	- finally, we must map '/thanks' to the ThanksHandler

###########
# Our app so far
###########

import webapp2
import cgi

months = ['January',
	'February',
	'March',
	'April',
	'May',
	'June',
	'July',
	'August',
	'September',
	'October',
	'November',
	'December']

month_abbvs = dict((m[:3].lower(), m) for m in months)

def valid_month(month):
	if month:
		short_month = month[:3].lower()
		return month_abbvs.get(short_month)

def valid_day(day):
	if day and day.isdigit():
		day = int(day)
		if day > 0 and day <= 31:
			return day

def valid_year(year):
	if year and year.isdigit():
		year = int(year)
		if year > 1900 and year < 2020:
			return year

def escape_html(s):
	return cgi.escape(s, quote = True)

form = """
<form method="post">
	What is your birthday?
	<br>
	
	<label> Month
		<input type="text" name="month" value="%(month)s">
	</label>
	
	<label> Day
		<input type="text" name="day" value="%(day)s">
	</label>

	<label> Year
		<input type="text" name="year" value="%(year)s">
	</label>

	<div style="color: red">%(error)s</div>

	<br>
	<br>
	<input type="submit">
</form>
"""

class MainHandler(webapp2.RequestHandler):
	def write_form(self, error="", month="", day="", year=""):
	# We will be calling this instead of:
	# self.response.out.write(form)
	# Because it let's us substitute in error messages
		self.response.out.write(form % {"error": error,
			"month": escape_html(month),
			"day": escape_html(day),
			"year": escape_html(year)})

	def get(self):
		self.write_form()

	def post(self):
		user_month = self.request.get('month')
		user_day = self.request.get('day')
		user_year = self.request.get('year')

		month = valid_month(user_month)
		day = valid_day(user_day)
		year = valid_year(user_year)

		if not (month and day and year):
			self.write_form("That doesn't look valid to me, friend.",
				user_month, user_day, user_year)
			# We've used our error message!
		else:
			self.redirect("/thanks")

class ThanksHandler(webapp2.RequestHandler):
	def get(self):
		self.response.out.write("Thanks! That's a totally valid day!")

app = webapp2.WSGIApplication([('/', MainHandler),
	('/thanks', ThanksHandler)],
	debug=True)

##########
# End of app
##########


#####################################
# Problem Set 2
#####################################

- Make a site to ROT13 some text
	- ROT13 is a simple encryption algorithm, where you increment every letter by 13
	- Running it through twice should convert it back to the same word
	- It should:
		- preserve case
		- preserve punctuation
		- preserve whitespace (including new lines)

- Example at:
udacity-cs253.appspot.com/unit2/rot13

##########
# My solution
##########

import webapp2

def escape_html(text):
	html_escape_table = {"&": "&amp;", '"': "&quot;", "'": "&apos;", ">": "&gt;", "<": "&lt;"}
	return "".join(html_escape_table.get(c,c) for c in text)

doc = """
<!DOCTYPE html>
<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Unit 2 Rot 13</title>
	<style type="text/css"></style>
</head>

<body style="">
	<h2>Enter some text to ROT13:</h2>
	<form method="post">
		<textarea name="text" style="height: 100px; width: 400px;">%(text)s</textarea>
		<br>
		<input type="submit">
	</form>
</body>
</html>
"""

class MainHandler(webapp2.RequestHandler):
	def write_form(self, text=""):
		self.response.out.write(doc % {"text": escape_html(text)})

	def rot13(self, s):
		transformed = ""
		for c in s:
			if c.isalpha():
				if c.isupper():
					c = c.lower()
					transformed += self.switch(c).upper()
				else:
					transformed += self.switch(c)
			else:
				transformed += c
		return transformed

	def switch(self, c):
		first = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m"]
		last = ["n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z"]
		if c in first:
			return last[first.index(c)]
		else:
			return first[last.index(c)]

	def get(self):
		self.write_form()

	def post(self):
		user_input = self.request.get('text')
		transformed = self.rot13(user_input)
		self.write_form(transformed)

app = webapp2.WSGIApplication([('/', MainHandler)],
	debug=True)



#####################################
# Lesson 3: Databases
#####################################

- Databases are quite complex
	- We'll split the lesson into 2 parts:
		- 1) We'll talk about SQL
		- 2) We'll talk about Google App Engine's implementation

- What is a database?
	- A program that stores and retreives data
		- Particularly large amounts of structured data
	- Note that databases are often stored on a separate server, or even a system of servers
		- So sometimes "database" refers not to the program, but to the machine or system of machines
		- Same as how "web server" could refer to a program/machine/system of machines

- Tables
	- In almost all databases
	- Example: building a site like reddit
		- users post links
		- other users can vote on links
		- they show what's most popular
	- Tables:
		- Links
			- Columns (type):
				- ID (int)
				- votes (int)
				- user (int)
				- date (date)
				- title (str -> could also be called "text", "varchar", etc.)
				- url (str)
	- Let's play around with link type data in Python!
		- See play.py for how we played around with this data in Python
		- Note that it's a bit tedious, and a db could make it easier!

- Why databases?
	- downsides of querying by hand
		- error prone (have to custom write every query)
		- tedious
		- SLOW
		- can handle more data than you can fit in memory

- Types of databases
	- Relational/SQL databases
		- Examples:
			- PostgreSQL
				- Used by reddit, hipmunk, etc.
			- MySQL
				- Used by almost everyone
			- SQLite
				- Light weight, simple db
			- Oracle
	- Google App Engine's Datastore
		- Lots of similarities to relational DBs, but also some differences
	- Amazon Dynamo
		- See their paper
	- NoSQL
		- e.g. mongo, couch
		- try to solve some of the limitations that SQL places on you

- SQL
	- Structured Query Language
	- invented in the 1970s
		- designed to solve pre-web problems
	- basic query:
		SELECT * FROM links WHERE id = 5;
	- "fetch all columns from the links table, and return only rows where the id is 5"

- We'll be playing around with SQL by using import sqlite3
	- this lets us use SQL in Python
	- see play.py

- Joins
	- I know how they work
	- But he uses different syntax:
		- For example, say we have a user table and a link table
		- We only know the users name (in the user table, but not the link table)
		- We want all data from the link table for this user
		SELECT link.* FROM link, user WHERE link.user_id = user_id AND user.name = 'Spez'
	- HOWEVER, we don't use joins often when writing web applications
		- We'll get into why later (they're slow?)

- Indexes
	- So far we've been doing sequential scans
		- i.e. looking through a link from left to right
		- This is slow with a lot of data
	- Indexes make lookups faster
		- Example: hash tables
			- We hash and index the value of the key, so we don't have to look up the keys sequentially
	- See play.py for indexing examples
		- From the add_new_link(link) function, we can see that there's a cost to having indeces
			- Though they make lookups faster, they also make extra work when you're adding new rows
			- Faster reads, slower inserts (and generally slower writes in general, even when updating data)
	- Example of creating an index:
		CREATE INDEX hotel_id ON hotels(id);
		- We've named the index hotel_id, it's created on the hotels table, and specifically on the id field
	- To get rid of an index:
		DROP INDEX hotel_id;
	- PostgreSQL
		- EXPLAIN ANALYZE
			- Just throw that in front of a query, and it'll say what it did!
			- You can see how much faster queries run on indexed fields

- Indexes for sorting
	- hastables are not sorted
		- you lose sorting info when you use a hashtable
	- trees are a different datastructure, a different type of mapping
		- tress are sorted!
		- however, the lookups are slower
	- hashtables have constant time lookups
		- not really dependent on the number of elements in the table
	- trees have log n time lookups

- Reddit Hotness Algorithm
	- computed using a special index
	- start with the link table
		- one of the fields is 'score'
			- it's a floating point field
			- there's an index on this field
		- every time there's an up or down vote, the score is re-calculated
			- score = hot(ups, downs, date)
			- why is date in there?
				- later (newer) date = higher score
				- this is what keeps the newest links near the top!
	- then you can just:
	SELECT * FROM links ORDER BY score DESC
	- to get the links ordered with the hotest ones at the top!
	- note that this would be a tree type index
		- the db actually keeps the records ordered in order of Hotness
		- this makes it super fast to pull them out in the right order

- Scaling Databases
	- Why would you need to scale a DB?
		1) Too much load
			- a single machine can't keep up with all the requests
			- one solution:
				- replicate the db
				- all writes go to a single master db
				- this db gets replicated accross two slave DBs
				- now we have 3 dbs with all the data on it
					- more machines to handle the requests!
				- you generally have a lot more reads than writes
					- as long as master can keep up with the writes, the slaves can just handle the reads
				- downsides:
					- doesn't increase write speed
					- replication lag
						- what if you try to read the data from the slave before its been uploaded!
		2) Too much data
			- you literally cannot store all the data on one machine
			- one solution: shard the db
				- one db holds links 1-100, the next holds 101-200, etc.
				- or you can use a hashing approach, where you hash on a specific key (i.e. link ids)
			- also solves the "too much load" issue, as you now have a lot of machines sharing the load
				- can handle large read load AND large write load!
			- downsides:
				- queries get much more complex
					- i.e. what if you try to get all the links sorted by hotness!
						- where do they reside?
						- you have to do a range query, which hits all the machines, you lose the 
				- joins becomes difficult, or even impossible
				- you probably need to design your data in a way that you don't need to do joins or complex queries
				- the database we'll be using in this class (Google Data Store) is like this:
					- we can't do joins, and a number of other things
					- BUT it's very fast and stable

- ACID
	- Stands for:
		- Atomicity
			- all parts of a transaction succeed or fail together
			- transaction = group of statements
			- i.e. say we're updating multiple rows in a db together, in one cohesive unit (i.e. in reddit example, we'd increase the score of the link and user together)
			- so these grouped jobs always succeed or fail together
		- Consistency
			- the DB will always be consistent
			- i.e. the db will always move from one valid transaction to the next
			- so, for example, you can't read a specific piece of data until the write on that data is done
		- Isolation
			- no transaction can interfere with another
			- i.e. say you have an upvote and a downvote
			- you should make sure they BOTH apply, not just one with the other failing
		- Durability
			- once a transaction s committed, it won't be lost
				- even if the db is turned off, unplugged, etc. we won't lose the data
	- It's hard to have a DB that really fulfils all of this

- Google App Engine Datastore
	- what they call 'entities' are basically tables
		- columns are not fixed
			- adding/changing them is easy
			- even entities of the same type don't have to have the same columns
				- sometimes adding columns to dbs with lots of data is hard, with app engine it isn't
		- entities all have an ID
		- entities have parents/ancestors
			- these are relationships to other entities
			- say we have an entity called Link
			- It might have a parent called Reddit
				- You can do things like "get me all Links that are children of Reddit"
				- can help with consistency
	- uses GQL instead of SQL
		- all queries begin with SELECT *
			- no way to select columns
		- no joins
		- all queries must be indexed
			- for the most part, Google App Engine will build the indeces for you, though you can define your own too
	- can use a procedural language instead of GQL if you want
	- the datastore is sharded and replicated
		- you won't have to think about scaling (too much)
		- queries will be quick (because they have to be simple)
		- we WILL have to think about consistency
			- because things are sharded/replicated, so updates can take time to fully propogate through the system
	- Check out the documentation here, no need to learn everything first:
		https://developers.google.com/appengine/docs/python/storage

- We're going to build a website, right now, called 'ASCII Chan'
	- it'll be a website for sharing ASCII art
	- a 1 page site
	- a form on top to submit ASCII art, with some previously submitted ASCII art below

**** Next bunch of lessons - just me working on ascii_chan!

- Google App Engine Datastore Types:
	Integer
	Float
	String (<500 chars, indexed)
	Text (>500 chars, can not be indexed.  Can't say "get me stuff where Text = x")
	Date
	Time
	DateTime
	Email
	Link
	PostalAddress
	etc.

- HTML <pre> tag
	- like <div>, but contains pre-formatted text
	- basically, preserves whitespace, newlines, etc.


#####################################
# Problem Set 3 - Building a Basic Blog
#####################################
- Front page that lists entries (can list all, or 10 most recent)
- Form to submit new entries
	- must check for errors, to make sure both fields (title and content) are there
- If successful, should re-direct to a permalink page for a specific entry
- Example:
udacity-cs253.appspot.com/blog
# dispalys the content
udacity-cs253.appspot.com/blog/newpost
# for a form to enter new posts, with error handling

- Then submit blog url to udacity site


#####################################
# Problem Set 3 - Office Hours
#####################################
- MySQL vs. Postgres
	- Very similar, use whatever you like
- Why NoSQL?
	- Don't have to think everything through in advance
		- Don't have to pre-define all columns
		- Very hard to make changes to SQL dbs when you have a tonne of users (adding new columns, indexes, new data types)
		- No schema needed in NoSQL - no formal description of columns and data types
	- BUT a lot of these schema-less dbs are just not very good at the moment
		- limited stability, documentation lacking
	- For now, probably easier to just stick with MySQL/Postgres
- Why does Facebook use NoSQL?
	- FB uses a lot of MySQL actually!
	- FB used to use Cassandra, but I don't think they do anymore
- You can actually sort of do schema-less behavious in Postgres!
	- Just store one column as a big wad of JSON
- Why should we avoid joins?
	- They don't scale very well
		- Very difficult to handle accross multiple machines
	- Better to structure your data so everything is independent
		- Think of your dbs as large key-value stores
	- This DOES mean storing redundant data!
		- Storing things in multiple places
		- For example, on reddit they store a users karma on a link they submit, so they don't have to look it up
		- This means a bit more overhead, BUT easier scaling
	- For Hipmunk they do joins
		- only ~300K hotels, not that large
	- For reddit they don't
		- joining tables with billions of rows each = bad idea!


- Fancy Python syntax:

# What does this mean?
def foo(*a):
# "take all of the un-named arguments, and store them in a tuple"
# Don't have to pre-define the number of args!

def foo(*a):
	return a

foo()							# returns ()
foo(1, 2, 3)			# returns (1, 2, 3)

def foo(*a):
	return a[0]

foo(1, 2, 3)			# returns 1


# What about this?
def render(self, template, *a, **kw):
	t = jinja_env.get_template(template)
	return t.render(*a, **kw)
# the *a is for un-named arguments, i.e. 1
# 	Will be represented as a tuple IN THE FUNCTION DEFINITION
# the **kw is for named arguments, i.e. x = 1
# 	Will be represented as a dictionary IN THE FUNCTION DEFINITION
# BUT IN THE FUNCTION CALL, these tuples/dicts will be boken apart into function parameters!
# Not that *a and *kw don't have to be used, but it's a convention
# 	Sometimes also *args and **kwargs
# See here for more:
http://stackoverflow.com/questions/287085/what-do-args-and-kwargs-mean


- Web frameworks:
	- What do they do?
		- The piece of your program that:
			- speaks HTTP
			- parses URLs into paths/queries
			- passes things to handler functions
		- Something like django also does sessions, user handling, form control, etc.
			- can be good or bad
		- Ruby on Rails is very popular for Ruby
			- similar to django in that it does a lot for you
		- Google App Engine's is a bit more simplistic
	- Explain .yaml files
		- They're config files used in app engine
		- Says what libraries to load, what files to load first, etc.


- Project management
	- How to keep your code manageable?
		- Good to have one directory with all templates
		- Another dir with static files (CSS, JS, etc.)
	- In terms of Python files:
		- Good to have one main file that's the control
			- URL mapping, and the classes that the URLs map to
		- All of the database stuff in separate files
			- i.e. the classes that create dbs
		- Also good to have utilities files
			- For generating random strings, hash values, etc.
	- Generally good to pull things apart into lots of small, clean files
		- In this class, though, we've been jamming a lot into one file
		- Easier for a small project, bad for a big one


#####################################
# Lesson 4: User Accounts and Security
#####################################
- Gonna learn about:
	- cookies
	- hashing paswords, storing them securely

- Cookies
	- small file/piece of data stored in the browser for a website
	- takes this sort of form:
		name = value
		i.e. user.id = 12345
	- used a lot to store temporary info:
		- i.e. whether or not you're logged into a website
	- How they work:
		- browser makes request to website
		- server sends stuff back, including cookie
		- every time you visit website in the future, you send cookie data back to the server
	- Generally you can store:
		- ~20 cookies/site
		- cookies < 4kb (should be way smaller)
		- should generally not be multi-line
	- Cookies can only be stored for one domain
		- i.e. udacity.com can only store udacity.com cookies
		- this is really important, don't want other sites fucking around with your cookies, as they could then login as you on a different site!
			- all of this is enforced on the browser side
	- For SMALL pieces of TEMPORARY data, cookies can be a better place to store things than in a db
	- Good uses:
		- sotring login info
		- storing small amounts of temporary data to avoid hitting db
		- tracking you for ads
	- Bad uses:
		- storing user preference info
			- why bad?  Because it's temporary!  You want this data to survive!

- Cookie Headers
	- HTTP response (from server to user)
		- Cookies are sent in HTTP headers
		- The server's HTTP response will look something like this:
			Set-Cookie: user_id=12345
		- name is generally short, value can be up to 4kb
		- You can also set multiple cookies like this:
			Set-Cookie: user_id=12345
			Set-Cookie: last_seen=Dec 25 2011
	- HTTP request (from user to server)
		- Again in the header:
			Cookie: user_id=12345; last_seen=Dec 25 2011
		- Note how the browser puts everything into one line, separated by semi-colons
			- Thus generally easiest to avoid semi-colons in your cookies

- Let's use telnet again to check out cookies!
telnet www.google.ca 80
GET / HTTP/1.0
Host: www.google.ca
# hit return twice

- Get a massive response like this:
HTTP/1.0 200 OK
Date: Sat, 15 Feb 2014 23:56:09 GMT
Expires: -1
Cache-Control: private, max-age=0
Content-Type: text/html; charset=ISO-8859-1
Set-Cookie: PREF=ID=e2b0eee34fe24b49:FF=0:TM=1392508569:LM=1392508569:S=tO0H8uQB6MBqalKP; expires=Mon, 15-Feb-2016 23:56:09 GMT; path=/; domain=.google.ca
Set-Cookie: NID=67=gNsrj73VPiAvUdMsZoewx15k2vVacHPLB1DlufhOrIWO3QuVGiwxc2vdo_bx-tzv2QMY31RJ05MSAp1A-O3CrSBZRG8mBswjwazVjeoddtc-EAIvfPmUFg2_VDDicmgM; expires=Sun, 17-Aug-2014 23:56:09 GMT; path=/; domain=.google.ca; HttpOnly
P3P: CP="This is not a P3P policy! See http://www.google.com/support/accounts/bin/answer.py?hl=en&answer=151657 for more info."
Server: gws
X-XSS-Protection: 1; mode=block
X-Frame-Options: SAMEORIGIN
Alternate-Protocol: 80:quic

<!doctype html><html itemscope="" itemtype="http://schema.org/WebPage"><head><meta itemprop="image" content="/images/google_favicon_128.png"><title>Google</title><script>(function(){
window.google={kEI:"m
etc.

- We can see the cookies in there!  Let's take a deeper look at the first one:
Set-Cookie: PREF=ID=e2b0eee34fe24b49:FF=0:TM=1392508569:LM=1392508569:S=tO0H8uQB6MBqalKP; expires=Mon, 15-Feb-2016 23:56:09 GMT; path=/; domain=.google.ca
- One interesting thing, Google is storing multiple pieces of data in one cookie
	- name: PREF
	- value: ID=e2b0eee34fe24b49:FF=0:TM=1392508569:LM=1392508569:S=tO0H8uQB6MBqalKP
- Then after the ;, we have some parameters:
expires=Mon, 15-Feb-2016 23:56:09 GMT; path=/; domain=.google.ca
- So we see when it expires, and that it's relevant only to .google.ca/

- Let's look at the other cookie
Set-Cookie: NID=67=gNsrj73VPiAvUdMsZoewx15k2vVacHPLB1DlufhOrIWO3QuVGiwxc2vdo_bx-tzv2QMY31RJ05MSAp1A-O3CrSBZRG8mBswjwazVjeoddtc-EAIvfPmUFg2_VDDicmgM; expires=Sun, 17-Aug-2014 23:56:09 GMT; path=/; domain=.google.ca; HttpOnly
- name: NID
- value: 67=gNsrj73VPiAvUdMsZoewx15k2vVacHPLB1DlufhOrIWO3QuVGiwxc2vdo_bx-tzv2QMY31RJ05MSAp1A-O3CrSBZRG8mBswjwazVjeoddtc-EAIvfPmUFg2_VDDicmgM
- parameters:
expires=Sun, 17-Aug-2014 23:56:09 GMT
path=/
domain=.google.ca
HttpOnly
- The last bit means this cookie is relevant only to HTTP

- Another way to get just the headers:
curl -I www.google.ca

- Easier than telnet :)

- One last way to inspect cookies
	- Go into incognito mode so you don't have any existing cookies
	- go into dev tools
		- CMD-OPT-i
	- click network
	- now get surfing!
		- go to google.ca
		- now you can see all the requests!
			- click on one to see it
			- you can see both the response and request headers!
		- if you didn't have a cookie to start with, you will if you visit the same site again!

- Cookie parameters
	- e.g.:
Set-Cookie: name=steve; domain=www.reddit.com; path=/
- Note that path means "path starts with"
	- so this could apply to www.reddit.com/whatever
- This cookie will be sent to any domain ENDING in www.reddit.com.  Examples:
	www.reddit.com
	foo.www.reddit.com
- Won't be sent to:
	reddit.com
	foo.reddit.com
- You need at least two periods:
	- So you must at least set:
		.reddit.com

- Setting cookies:
	- When you send a cookie from:
		www.reddit.com
	- The default domain is:
		www.reddit.com
	- And you can only set to this domain or higher, e.g.:
		www.reddit.com
		.reddit.com
	- But not something like:
		foo.reddit.com

- Receiving cookies:
	- Which domains would receive the cookie set like this?
		Set-Cookie: user=123; Domain=ide.udacity.com
	- Would receive it:
		- ide.udacity.com
		- other.ide.udacity.com
		*** so the domain and sub-domains can receive it
	- Wouldn't receive it:
		- udacity.com
		- other.udacity.com

- Setting cookies (2):
	- Which domains could set this cookie?
		Set-Cookie: user=123; Domain=ide.udacity.com
	- Can set it:
		- ide.udacity.com
		- other.ide.udacity.com
		*** so the domain and sub-domains can set it
	- Can't set it:
		- udacity.com
		- other.udacity.com

- Browser settings:
	- We can do things like:
		- accept all cookies
		- accept cookies for the current session only
		- block all cookies
		- block 3rd party cookies
			- i.e. if I'm on reddit, ALLOW reddit cookies, but BLOCK google cookies!
	- For yourself, often good to block 3rd party cookies

- Ad Networks:
	- How they work:
		- Your browser makes a request to a website
		- The server responds to the HTML
		- IN THE RESPONSE IS A 1px IMAGE!
			- This image makes a request to a different server, i.e. google.com
			- google.com responds with the image itself, and with a cookie!
		- Worth noting that this will be a google.com cookie
			- udacity can't set it, but google can!
			- this is a 3rd party cookie
	- This could be used for Google analytics, but also for ad network tracking!
		- now Google knows that you've been to reddit.com
		- say you now visit pets.com
			- pets.com returns HTML and a tracking pixel
		- now Google knows you've been to both reddit.com and pets.com
		- So now they can deliver ads that are more relevant to you

- Cookie expiration
	- If you just set a cookie like this:
		Set-Cookie: user=123
	- It's a "session cookie"
		- Will expire when the browser is closed
	- If you want it to persist:
		Set-Cookie: user=123; Expires=Tue, 1 Jan 2025 00:00:0 GMT
	- So when you see those logins with "remember me" check-boxes
		- If you check it, you get an expires parameter
		- Else it's a session cookie, gets deleted when you close your browser

- Using cookies with app engine!
*** See app engine code

- We can set and play with cookies like this:

class BlogHandler(Handler):
	def get(self):
		# app engine automatically parses cookies, and throws them into a dictionary-like object, "cookies"
		# we can call the dict-version of get on it:
		visits = self.request.cookies.get('visits', 0)
		# get's the value of 'visits' if it's there, else 0
		# So if I've never if I've never been here before, this starts at 0
		# Now increment:
		if visits.isdigit():
			visits = int(visits) + 1
		else:
			visits = 0
		# Now set this in the cookie:
		self.response.headers.add_header('Set-Cookie', 'visits=%s' % str(visits))
		# Now use it
		if visits > 25:
			self.write("You are the best ever!")
		else:
			self.write("You've been %s times!" % visits)

- Hashing
	- What is a hash?
		H(x) -> y
	- A hash takes in x (data) of any size
	- A hash outputs a value y, which is a fixed length string
		- generally 32-256 bits
	- It should be super hard to generate a specific y
	- Likewise, it should be super hard to find x from a given y
	- You shouldn't be able to modify x without significantly modifying y
		- changing 1 bit in x should make y completely different
			- very little corellation between x and y

- Hash algorithms
	- don't write your own!
		- at least for security purposes
	- Some popular algorthms:
		- crc32
			- used for checksums
			- very fast
			- a simple way to check that you've got the whole file
				- send the file and the hash, then make sure that the file hashes to the hash
			- not for security
			- definitely possible for two values to hash to the same value
				- easy to have these "collisions"
		- md5
			- pretty fast
			- used to be thought to be pretty secure
				- BUT it's been broken repeatedly over the last few years
				- it's also now easy to find collisions
					- given a y, it's easy to find a different x that hashes to it
		- sha1
			- not quite as fast
			- pretty secure, just now starting to get broken
			- just starting to find collisions
		- sha256
			- slower
			- quite secure right now

- We'll be using sha256

- Playing around with python in the terminal
python
import hashlib
x = hashlib.md5("foo!")
x
x.hexdigest()
# gives us the string that "foo!" hashes to
# for foo! it's:
# 35af8b7a9490467f75f19c1e5459f7e7
# for foO! it's:
# 4a037b06903e4b4c6605785aebbe709a
# Totally different!

- for sha256, exactly the same, but just replace md5 with sha256

- Hashing cookies:
	- We want to prevent people from "cheating"
		- i.e. modifying their own cookies, sending us back fake data
	- Instead of just saying:
Set-Cookie: visits=5,[hash of 5]
	- now the user can't fake it without knowing what hash we used!
	- then when we get a value from the browser, like:
	5,absdfsghdfh3984237423894
	- we can hash 5, and make sure it's the same as the hash!
		- if it doesn't, we know the cookie is invalid and we can throw it out

- Implement a function make_secure_val(s)

import hashlib

def hash_str(s):
	return hashlib.md5(s).hexdigest()

def make_secure_val(s):
	return "%s,%s" % (s, hash_str(s))

- Now make a function to check if this is correct!
	- it should return the value if it's correct, else return None

def check_secure_val(h):
	val = h.split(',')[0]
	if h == make_secure_val(val):
		return val

- Now let's use these functions in our program!

# Handler for the page displaying posts
class BlogHandler(Handler):
	def get(self):
		# self.render_blog()
		self.response.headers['Content-Type'] = 'text/plain'
		visits = 0
		visits_cookie_str = self.request.cookies.get('visits')
		if visits_cookie_str:
			cookie_val = check_secure_val(visits_cookie_str)
			if cookie_val:
				visits = int(cookie_val)

		visits += 1

		new_cookie_val = make_secure_val(str(visits))

		self.response.headers.add_header('Set-Cookie', 'visits=%s' % new_cookie_val)

		if visits > 25:
			self.write("You are the best ever!")
		else:
			self.write("You've been %s times!" % visits)

- So now the user can only "fake" their visits if they know what hash we're using!

- But what if they know what hash we're using?
	- We need an extra secret!
		- instead of just:
		H(1) = [HASH]
		- we can:
		H(SECRET+1) = [HASH]
		- Now if they don't know our secret, it's going to be super hard for them to break our hash!

- Another note:
	- so far we've been using the Python library:
		hashlib
	- but even better is:
		HMAC
			- which stands for "Hash-based Message Authentication Code"
			- it's a special algorithm for adding these keys/secrets into hashes easily
	- We use it something like this:
		hmac(secret, key, hash_function)

- Using hmac in console:
python
hmac.new("secret", "udacity").hexdigest()

- To make our old code switch to hmac
import hmac
SECRET = 'imsosecret'
def hash_str(s):
	return hmac.new(SECRET, s).hexdigest()

- So to recap:
	- visits = 1
		- very insecure
	- visits = 1|md5(1)
		- almost as insecure
	- visits = 1|HMAC(secret,1)
		- very secure

- This kind of cookie protection is excellent to valid important cookie data like user ids
	- don't want to let people appear to be logged in to someone else's account!

- password hashing
	- imagine we have a table "user" with 2 fields:
		- name
		- password
	- we would then be checking passwords something like this:

def valid_user(name, pwd):
	user = get_user(name)
	if user and user.password == pw:
		return user

- but what if our db gets compromised!
	- we should instead be storing HASHED passwords!
		- so the table fields become:
			- name
			- password_hash
	- then checking them will look more like:

def valid_user(name, pwd):
	user = get_user(name)
	if user and user.password_hash == H(pw):
		return user


- RAINBOW TABLES
	- basically a dictionary of what all sorts of passwords hash to
	- how to account for these?
		- we salt the passwords!
			- very similar to 
			- then we simply store:
				- h, salt
				- where h = H(pw + salt)
				- so even though the salt is right there, it makes it way harder to reverse engineer

- Quiz:
	- implement a function make_salt() that returns a string of 5 random letter

import random
import string

def make_salt():
	return ''.join(random.choice(string.ascii_letters) for x in range(5))

print(make_salt())

- implement the function make_pw_hash(name, pw) that returns a hashed password of the format: 
	- HASH(name + pw + salt),salt
	- use sha256

import hashlib

def make_pw_hash(name, pw):
	salt = make_salt()
	h = hashlib.sha256(name + pw + salt).hexdigest()
	return "%s,%s" % (h, salt)

print(make_pw_hash("bob","324dfgdg"))



- Ok, now we need to check if a password is valid!
# Implement the function valid_pw() that returns True if a user's password 
# matches its hash. You will need to modify make_pw_hash.

#h = make_pw_hash('spez', 'hunter2')
#print valid_pw('spez', 'hunter2', h)

import random
import string
import hashlib

def make_salt():
	return ''.join(random.choice(string.letters) for x in xrange(5))

def make_pw_hash(name, pw, salt = None):
	if not salt:
		salt = make_salt()
	h = hashlib.sha256(name + pw + salt).hexdigest()
	return '%s,%s' % (h, salt)

def valid_pw(name, pw, h):
	salt = h.split(',')[1]
	return make_pw_hash(name, pw, salt) == h

# Testing it
h = make_pw_hash('bobby', 'joe')
print h
# h is what we'd store in the db
print valid_pw('bobby', 'joe', h)
# we'd pull h from the db to verify


- Password hashing:
	- most hashing functions are designed to be fast
		- this is a good thing for verifying cookies and whatnot
		- this is actually BAD for passwords
			- why?
			- if someone wants to brute force your passwords, you actually want that hashing function to be pretty slow!
			- a good hashing function to use is:
					bcrypt
			- nice and slow :)
	- we aren't using bcrypt in this course, because it's not built into Python by default, but it's better for passwords than sha256
		- there is a Python module for it, though
	- bcrypt basically takes an extra parameter, "how long do you want it to take"
		- you can make it stay slow even as computers get slower


- HTTPS
	- With everything we've done so far, the pw would be encrypted on your server
		- However, it WOULDN'T be encrypted in-transit
			- vulnerable to man in the middle
	- for encryption in transit, use HTTPS
		- HTTPS = HTTP + SSL


#####################################
# Problem Set 4 - User Accounts
#####################################

#################
Part 1:
#################

	1) Add registration to the blog (with valid cookie)
		- add a signup form page --> at domain/signup
			- Should have 4 fields:
				- Username
				- Password
				- Verify Password
				- Email (optional)
			- Check that Password and Verify Password match ()
				- if not, throw an error by Verify password stating "Your passwords didn't match."
				- *** SEE UNIT 2 FOR HOW TO CHECK ***
			- If the user already exists, throw an error saying that the user exists
	2) If they enter valid data, then:
		- cookie the user:
			should be something like:
				userid|hash
		- note that we're storing the id, not the username
		- Then, redirect to a welcome page at /welcome
			- This page should say: "Welcome, %s!" % username
				- get the username from the cookie
	3) If someone fucks with the cookie, then the cookie should no longer be valid, and you should be re-directed to the signup page


Instructor Notes

In order to be graded correctly for this homework, there are a few things to keep in mind. We'll be grading your web app by POSTing new users to your signup form and checking that we correctly get redirected and a cookie gets set. There are a few main issues you need to keep in mind in order for this to work:

We assume your form to signup new users is at a path of '/signup' from the url you enter. That is, if you enter 'www.myblog.com/blog' in the text field above, then the form is at 'www.myblog.com/blog/signup'. The form method must be POST, not GET. The form input boxes must have the names 'username', 'password', 'verify', and 'email' in order for the grading script to correctly post to them. Don't forget to escape your output!
Also, the basic methods you'll use to set and get cookies are as follows: In order to get a cookie you receive from the user, you can use 'self.request.cookies.get(name)', where name is the name of the cookie you are looking for. In order to send a cookie to a user, you simply add the header to your response. For example, 'self.response.headers.add_header('Set-Cookie', 'name=value; Path=/')', where name is the name of the cookie, and value is the value you're setting it to. The default Path for a cookie is the current path, which is probably not what you want. The Path parameter should be / as in our example.

If you're interested in the css styling file we use for the example page, the link is:
http://udacity-cs253.appspot.com/static/main.css


#################
Part 2:
#################

Implement login
	Login page should be at /login
	It should have a header login, two fields (Username and Password), and a submit button
	If you type in a valid username and password, it sets the cookie (same cookie as signing up), and redirects you to the welcome page
	Any invalid login (wrong password OR a username that doesn't exist), you get an "Invlaid login" error


#################
Part 3:
#################

Implement logout
	Logout page should be at /logout
	It doesn't even need its own actual page, it should just clear your cookie (set it to nothing), then re-direct you to the signup page


#####################################
# Lesson 5: APIs
#####################################

APIs
	Basically, design your site to send note only HTML (good for humans), but also JSON or XML (good for computers)
In this lesson, we'll add a feature to ASCII chan so that we can see where users are submitting data from

So far, we've been looking at users making requests to servers, and getting responses
	Now we'll look at the same idea, but servers making HTTP requests to other servers

Case study: Hipmunk
	1) User does flight search
		HTTP request from user to server
	2) Himunk server makes a bunch of HTTP requests to airlines, etc.
		HTTP request from server to server
	3) These other servers send their data back
	4) Hipmunk servers manipulate this data, form a response that they send back to the user

Big question - how do we make our server speak to other servers, with no browser involved?
	In Python, the urllib2 library is a good way to go
		See play2.py for examples

XML
	A regular way to express data between computers
	Looks a lot like HTML, example would be:

<?xml version="1.0" encoding="utf-8">
<results>
	<itinerary>
		<leg>
			<origin>CUS</origin>
			<dest>WAS</dest>
		</leg>
	</itinerary>
</results>

	XML has no void tags, like <br>, all tags MUST close!
		Through things like <br/> will work
	There's also a doctype xhtml, with the same rules
		Basically lets you send xml to a browser, and have it render like html
		Will actually render faster, since the browser has to do less complex parsing
	Both HTML and XML descend from SGML

Parsing XML:
	See play2.py for an example of simple XML parsing in Python

RSS
	RSS standas for RDF Site Summary
		RDF = Resource Description Framework
			An XML format for describing pretty much anything
	RSS also stands for "Really Simple Syndication"
		It's really just a list of content in XML
	i.e. if you have a blog with regular content, you could have an RSS reader to read it easily
	It's basically web pages written in XML instead of HTML, so that they can be easily parsed by computers

JSON
	JavaScript Object Notation
		JSON is actually valid JS code
	Basically just nested dictionaries/lists
		Dictionary keys must be strings?
	Anything that can be expressed in XML can be expressed in JSON
		But it's a little less verbose than XML
	Other than lists/dicts, you can have:
		int
		string
		boolean
		float
		null ---> i.e. []
	Also note that JSON must use double quotes to enclose strings, single quotes aren't allowed
	See play2.py for more

To see reddit's front page in JSON
	http://www.reddit.com/.json
	For a quiz related to it, see play2.py

A lot of websites have this feature, where you can get the data not just as HTML, but also as JSON and/or XML
	Twitter example:
		search.twitter.com/search.json?q=udacity
	Actually, that was the old version of the API, but the idea is good

JSON escaping
	This is valid JSON:
		{"story": "once upon a time"}
	This isn't:
		{"story": "once upon a" time"}
	We'd need to escape the '"'
	Backslashes are the key, but...
		{"story": "once upon a\" time"}
	That's not going to work with:
		json.loads('{"story": "once upon a\" time"}')
	Because we need to escape for Python AND for the JSON interpreter
	We actually need two back-slashes
		json.loads('{"story": "once upon a\\" time"}')
	Alternately, we can tell Python that this is a raw string - i.e. no escaping
		Then it will pass the raw string to the JSON interpreter, and the interpreter will pick up the escaping
	So a better way to write it is:
		json.loads(r'{"story": "once upon a\" time"}')
	Note the r at the start

Writing JSON
	The main time we have to worry about escaping is when WRITING JSON
	The functions:
		json.dumps (to a string)
		json.dump (to a file)
	Note the json.dumps is only going to work with lists, dicts, ints, strings
		If we want to use things like date/time, we'll have to convert to string first

How to be a good citizen on the internet
	1) Use a good user-agent
		- the header where you say who you are, what your name is, etc.
	2) Rate-limit yourself
		- try not to send requests super fast
		- for example, instead of:

while more:
	get_more_tweets()

		- we could use:

import time
while more:
	get_more_tweets()
	time.sleep(1)

		- time.sleep(1) will cause our interpreter to pause for one second

Common protocols/formats for communicating accross the internet
	SOAP (Microsoft)
		Nasty protocol
	Protocol buffers (Google)
		JSON-esque
	Thrift (Facebook)
		JSON-esque
	Plan-text, custom formats
		Bad idea, why not just use JSON?
	JSON
	XML


############
# Adding a feature to ASCII chan
############

- On the newpost page, draw a map showing where the most recent submissions come from
	- need a service that will convert IPs into locations
		- we'll use hostip.info
		- they've also got an API, where sending an IP here:
			api.jostip.info/ip=XXX_IPHERE_XXX
		- that will return XML with data on where the IP is

- then we'll be using Google Maps, specifically their static maps API, to draw a map of the posts
	- gives you a link that generates a static image of a map with markers

- debugging notes:
	- find some way to print the coords that you're pulling
		- also make sure it's not localhost (127.0.0.1), as that won't have a location associated with it

- Here's the static map example from Google's API:

http://maps.googleapis.com/maps/api/staticmap?center=Brooklyn+Bridge,New+York,NY&zoom=13&size=600x300&maptype=roadmap
&markers=color:blue%7Clabel:S%7C40.702147,-74.015794&markers=color:green%7Clabel:G%7C40.711614,-74.012318
&markers=color:red%7Clabel:C%7C40.718217,-73.998284&sensor=false

- Which is really:

http://maps.googleapis.com/maps/api/staticmap
	?center=Brooklyn+Bridge,New+York,NY
	&zoom=13
	&size=600x300
	&maptype=roadmap
	&markers=color:blue%7Clabel:S%7C40.702147,-74015794
	&markers=color:green%7Clabel:G%7C40.711614,-74.012318
	&markers=color:red%7Clabel:C%7C40.718217,-73.998284
	&sensor=false

- All that is required is:
http://maps.googleapis.com/maps/api/staticmap
	&size=600x300
	&sensor=false

- The sensor bit is to find out where the user is, if you're on a phone or something like that, that already knows
	- we won't use it
- The markers are the spots on the map to mark!
	- the colors and labels aren't even required


#####################################
# Problem Set 5 - JSON
#####################################

- Make you blog output JSON, when the URL ends with .json
	- i.e. blah.com/blog.json
- the JSON should be a list of dictionaries
- alternately, visiting a permalink should also work
	- for example, visiting blah.com/blog/234535353456.json
	- this should return just a dictionary:
		{
			"content": "What a great blog",
			"created": "Thu Apr 12 03:04:21 2014",
			"last_modified": "Thu Apr 12 03:04:21 2014",
			"subject": "Hello World"
		}
	- note that dates aren't in the JSON library, will have to encode ourselves
		- look into strftime()
- Another note, while debugging the site with Chrome dev tools, make shure to check out the "network" tab
	- when we go to a .json page, make sure that in the response header we see:
		Content-Type: application/json; charset=UTF-8
	- this is a header we'll have to set

#####################################
# Office Hours 5
#####################################

- Debugging:
	- At the top:
	import logging

	- In development/stagin mode, at the top you put:
	DEBUG=True

	- In production:
	DEBUG=False

	- The throughout the code you can use:
	logging.debug("string")

	- Which will print the string to the console if you're in DEBUG mode

	- If you want to log errors in production logs, use:
	logging.error()

- Testing:
	- Really hard to test the behaviour of a web app
	- One cool thing - run the last ~10,000 production requests in your development/staging environment, see if there are errors!

- Security:
	- Major vulnerabilities to think about:
		- xss
			- cross site scripting
			- when you accept data from a user, and you display it in the web page without escaping it
			- for example, say you let a user put their entry into a <textarea>
			- they code put code in a <script> tag, which could fetch cookies and other such thing
			- escaping the HTML can fix this, but if you don't want to escape ALL html (i.e. on a blog, where you want them to be able to bold, use links, etc.), then you have to escape just some html
				- markdown can be a good way to go
				- let's people use links and images, but not all html
		- SQL injection
			- very similar to xss
			- i.e. say you have this code:
				"SELECT * FROM Link WHERE id = %s" % _id
			- but what if they can add arbitrary stuff, like DROP TABLE!
			- they could really fuck you up
			- You want to include a wrapper around your SQL:
				- app engine provides this with the GQL query objects
			- SQLAlchemy is a really popular Python SQL library
				- let's you write SQL ina procedural language, which can be nice
				- has an ORM, which maps Python objects to SQL, BUT THESE SUCK
					- they can really slow your site down if used improperly
		- memcache injection
			- similar to SQL injection, but polutes your memcache
		- CSRF
			- forms have an action attribute, which say where you want to submit your form to
			- let's you submit forms to an arbitrary site
			- you can get users submit to a different site
			- the way to prevent this is to include hashes (or some sort of secret) on the page you want to be actually submitting forms, and then only accept post requests that come with that secret

- Relying on parsing/scraping data from sites
	- For example, Hipmunk relies on the structure of the Amtrak site
	- What if they change the structure?
	- Then it breaks, and you must fix it
		- No great solution, just fix things when they break

- How do you do internationalization/localization?
	- Not that hard
	- A good Python package is gettext:
		- put all your strings in one function, then this function can have the ability to translate stuff
		- basically, Google for gettext to learn more

- Soap
	- Soap is awful, never use it if you can avoid it
	- use XML/JSON whenever you can

- Paths
	- Ending URLs in "/", how to handle this?
	- Often best to just match with or without the trailing slash, like this:
		- "/blog/?"

- Production
	- How to have a distinction between production and development?
		- One way:
			- Have a couple files, for example:
				production.py
				devel.py
			- These will have a bunch of global variables, like secret keys
			- Have one that's only used in production, and one only in development
			- When you deploy code, symlink config.py to either production.py or devel.py
	- Basic idea though is to store global vars in a file you can switch out for production

- Next steps after this class?
	- Get good at JavaScript and CSS


#####################################
# Lesson 6: Caching
#####################################

- When you start operating at a large scale, lots of things can break down
	- can run out of bandwidth, disk space, processing power, etc.

- Why scale?
	1) So we can serve more requests concurrently
		- basically, lots of connections at once
		- every connection takes memory, CPU, etc.
	2) So we can store more data
		- sometimes you have too much data for memory, one marchine, disk space, speed, etc.
	3) So we're more resilient to failure
		- i.e. database replication
		- if one db fails, you don't lose data
	4) So we can serve more requests faster
		- similar to serving more requests concurrently, but this will generally require a better machine, caching, etc.

- What do we scale?
	1) Bandwidth
		- especially for sites like youtube, justintv
	2) Computers (memory, CPU)
		- CPU is very often limiting, if your website does a lot of computation
		- memory can be an issue if you're storing/caching a lot of data in memory
	3) Power
		- more computers = more power
		- for example, Google needs to think about building data centres near big power sources
	4) Storage
		- especially if users are submitting lots of content to you
		- how do you store it all?
		- think Facebook with all of their photos
		- or Google, they more or less store the entire internet accross their machines, so they can search fast!

- Techniques for scaling
	1) Optimize code
		- it does mean more developer cost, but often optimizing code is better than adding machines
		- this really just comes down to programming better, understanding how compilers work, etc.
	2) Caching complex operations
	3) Upgrade machines
		- more memory
		- more disk space
		- faster CPU
			- can be cheaper/easier than optimizing code
	4) Add more machines
		- can be tough, but ultimately you'll have to do this eventually

- Caching
	- storing the RESULT of an operation, so that future requests return faster
		- don't have to do the computation again
	- When do we cache?
		1) When the computation is slow
		2) When the computation will run multiple times
		3) When the output is always the same for a particular input
		4) When your hosting provider charges for db access (i.e. Google App Engine!!!)

- Example:
	- Say we have this function:
		db_read()
	- It's slow, takes 100ms
		- So if we get a lot of requests, we can only do 10 per second
	- How would we cache this?
		- in pseudo-code:

if request in cache:
	return cache[request]
else:
	r = db_read()
	cache[request] = r
	return r

	- The cache is a hashtable:
		- maps keys (requests) to values (result of request)
	- In the above:
		- the "if" block is a "cache hit", while the "else" block is a "cache miss"
	- A lookup from a hashtable is often < 1ms, way better than 100ms!

- So the idea is just to wrap the slow bits of your code in a caching algorithm
	- Example:

import time

# complex_computation() simulates a slow function. time.sleep(n) causes the
# program to pause for n seconds. In real life, this might be a call to a
# database, or a request to another web service.
def complex_computation(a, b):
	time.sleep(.5)
	return a + b

# QUIZ - Improve the cached_computation() function below so that it caches
# results after computing them for the first time so future calls are faster
cache = {}
def cached_computation(a, b):
	key = (a, b)
	if key in cache:
		r = cache[key]
	else:
		r = complex_computation(a, b)
		cache[key] = r
	return r

# Note that time.time() returns the current time since some epoch, in seconds
start_time = time.time()
print cached_computation(5, 3)
print "the first computation took %f seconds" % (time.time() - start_time)
# So we compare the time at the start and end of the computation, cool!

start_time2 = time.time()
print cached_computation(5, 3)
print "the second computation took %f seconds" % (time.time() - start_time2)


- Ok, let's get to a more real-world example, scaling ASCII chan!
	- When a user makes a request to ASCII chan, we have to:
		1) Process the request
			- HTTP, URL, handler
			- this can take a bit of time, but not a tonne
		2) Then we query the database
			- this can take a lot of time
			- it can also mean we have to pay App Engine
		3) Collate the results
			- i.e. getting ready to render the HTML
		4) Render HTML
			- this can actually take some time too!

- Querying the database is almost always the slowest step
	1) First step is to optimize the db itself
		- make sure you have the proper indexes, make sure your queries are sane/easy, etc.
		- Google App Engine makes indexes for us
			- BUT they may not be optimal, in which case we'd have to make one by hand
	2) You could add more machines
		- In this case, we don't have control over replication, sharding, etc.
		- Note that this is VERY complex, it should be your last resort
	3) Bigger machines
		- again, not too relevant with app engine, though can be a good option
	4) Cache the query

- *** BUNCH OF WORK IN ascii_chan BRANCH ***

- Cache stampede:
	- Think of this situation:
		- 1 user posts to db, which clears the cache
		- BUT we then also have a tonne of users access the site
		- THEY all see an empty cache, so they all think they need to read from the db!
			- they all run the same query on the db
	- Cache stampede = multiple cache misses mean to much load (on the db, or on any other slow process)
	- How to avoid?
		- DON'T CLEAR THE CACHE!
		- instead, just overwrite it with new data!
			- then these users will just get slightly old data, which is generally not a big deal

Caching Techniques:

- NO CACHING
	- DB read/pageview
	 - every
	- DB read/submit
		- none
	- Bugs?
		- none, but slow

- NAIVE CACHING
	- DB read/pageview
	 - cache miss
	- DB read/submit
		- bugs
	- Bugs?
		- Yes, front page becomes stale

- CLEAR CACHE
	- DB read/pageview
	 - cache miss
	- DB read/submit
		- none
	- Bugs?
		- none, but can have cache stampede

- REFRESH CACHE
	- DB read/pageview
	 - rarely
	- DB read/submit
		- 1
	- Bugs?
		- none
	- KEY POINT:
		- "Simple" users (not logged in) shouldn't be touching the db

Most aggressive caching method:

- UPDATE CACHE
	- DB read/pageview
		- 0
	- DB read/submit
		- 0
	- Bugs?
		- none

- Cache updating:
	- Whenever we have a read
		1) Send the write to the db
		2) Also send the write TO THE CACHE
	- The only db read is when you start up the app for the first time, and get that first request!
		- This is how reddit currently works
	- The tradeoff:
		- Complex inserts + speed vs. db reads
	- THE MORE ACCURATE THE CACHE, THE MORE COMPLEX THE CODE

- App server scaling
	- Let's think again about what happens during a request:
		1) Process request
		2) DB query
		3) Collate results
		4) Render HTML
	- We've improved "2)", but what about the rest?
		- We can use caching for rendering HTML too
		- We can also add additional app servers for all of 1, 3 and 4!
	- Multiple app servers
		- More machines to handle more requests (all can access same db)
		- How to implement?
			- Stick a load balancer between user and app servers
			- The load balancer is a physical machine, that's optimized for doing one thing: SPREADING REQUESTS ACCROSS MULTIPLE MACHINES
			- It does nothing but take requests, chose a machine, and pass the connection along
	- App engine handles the multiple servers for you, but we should still understand how to use

- Load Balancing Algorithms:
	1) Random
		- Request comes in, load balancer randomly picks machine
	2) Round robin
		- Chose servers in order
	3) Load based
		- Know the load on each server, send to the least busy


# QUIZ - implement the function get_server, which returns one element from the
# list SERVERS in a round-robin fashion on each call.

SERVERS = ['SERVER1', 'SERVER2', 'SERVER3', 'SERVER4']

n = -1
def get_server():
	global n
	n += 1
	return SERVERS[n % len(SERVERS)]

print get_server()
print get_server()
print get_server()
print get_server()
print get_server()
print get_server()
print get_server()
print get_server()


- Why is our dictionary cache problematic with mutiple app servers?
	1) Multiple app servers = multiple caches, how do we keep them in sync?
	2) Each app server may have to hit the db to update its cache
		- can get a situation similar to the cache stampedes we talked about before

- A solution:
	- A shared cache!
	- A great piece of technology for this is memcached

- memcached
	- very fast, in-memory cache
	- built by Danja to power LiveJournal
		- A very popular site in the early 2000s
	- now pretty much everyone uses memcached!
		- essential piece of software when writing web apps
	- memcached is a process
		- often runs on own machine, but could run on an app server
	- same idea as the caching we talked about before:
		- app servers check memcached, if it has the value they use it, if not they hit the db
	- memcached is just a key value store, basically a big hash table
		- can easily be split accross different machines
		- this is generally handled by libraries

- memcached works with keys and values, both of which are strings
	- 3 main operations:
		set(key, value)
		get(key) -> value
		delete(key)

- ALSO, if your process re-starts, you don't have an empty cache


# QUIZ implement the basic memcache functions

CACHE = {}

#return True after setting the data
def set(key, value):
	CACHE[key] = value
	return True

#return the value for key
def get(key):
	return CACHE.get(key)

#delete key from the cache
def delete(key):
	if key in CACHE:
		del CACHE[key]

#clear the entire cache
def flush():
	CACHE.clear()

print set('x', 1)
print get('x')
print get('y')
delete('x')
print get('x')


- More advanced properties of memcached:
	- Entirely in memory
		- so it's fast
		- it's NOT durable, it's not on disk
		- limited by memory
	- what if you try to store more data in memcached than there is available memory?
		- throws away data that is least recently used

- Adding memcache to ascii_chan did some nice things:
	1) Cache survives restarts of app
	2) App is now STATELESS
		- this is the key to scaling
		- between any two requests, our app stores no state
		- our app servers are now interchangeable
			- we can now add or remove app servers, drama free
			- app servers can be scaled independently of memcached or db
		- basically, with this setup we can add more app servers, more memcached servers OR more dbs fairly easily
			- different apps will need more of one of these than another

STATE IS STORED IN COOKIES, DB OR MEMCACHED, BUT NOT THE APPS!

- Advanced cache updates:
	- Problem: multiple users submit at the same time, overwriting each other
		- With direct db access, this isn't a problem, dbs make everything happen sequentially
		- BUT with caching, this CAN be a problem
			- Say in db we have 1, 2
			- app server A says "add 3" to the db, then says to the cache "our current state looks like 1, 2, 3"
			- app server B says "add 4" to the db, so the db, now has 1, 2, 3, 4, BUT if it happened at the same time as app server Bs request, it's now overwriting the cache saying things look like 1, 2, 4!
		- Basically, on a db we can just say "insert this element", but in a cache we say "the list of elements is this"

- CAS
	- Stands for check and set
		gets(key) -> value, unique
		cas(key, value, unique) -> True
	- Example:
		- App 1 and App 2 both call:
			v, u = mc.gets(k)
		- So they get a value and it's unique
		- Then they both want to update
		- App 1 calls:
			mc.cas(k, y, u)
		- This works, and returns True
			- BUT IT CHANGES THE UNIQUE ASSOCIATED WITH THIS KEY/VALUE PAIR!
		- App 2 calls:
			mc.cas(k, y, u)
		- This doesn't work, it returns False!
		- Better to implement like this:

v, u = mc.gets(k)
r = mc.cas(k, y, u)
while r = False:
	v, u = mc.gets(k)
	r = mc.cas(k, y, u)

	- you would do this only when performing some sort of destructive operation, like updating a list
		- otherwise, overwriting could be fine

- Let's get a little deeper into our fake memcached!

# The code we had before:
CACHE = {}

#return True after setting the data
def set(key, value):
    CACHE[key] = value
    return True

#return the value for key
def get(key):
    return CACHE.get(key)

#delete key from the cache
def delete(key):
    if key in CACHE:
        del CACHE[key]

#clear the entire cache
def flush():
    CACHE.clear()

# QUIZ - implement gets() and cas() below
#return a tuple of (value, h), where h is hash of the value. a simple hash
#we can use here is hash(repr(val))
def gets(key):
    v = CACHE.get(key)
    if v:
      return v, hash(repr(v))

# set key = value and return True if cas_unique matches the hash of the value
# already in the cache. if cas_unique does not match the hash of the value in
# the cache, don't set anything and return False.
def cas(key, value, cas_unique):
    r = gets(key)
    if r:
      v, u = r
      if u == cas_unique:
        return set(key, value)
      else:
        return False

print set('x', 1)
#>>> True
#
print get('x')
#>>> 1
#
print get('y')
#>>> None
#
delete('x')
print get('x')
#>>> None
#
set('x', 2)
print gets('x')
#>>> 2, HASH
#
print cas('x', 3, 0)
#>>> False
#
print cas('x', 4, 6400019251)
#>>> True
#
print get('x')
#>>> 4


- Why do we split our services?
	1) So they can be scaled independently
	2) To increae fault tolerance
		- i.e. bad cache shouldn't ruin app server requests
	3) So two very different processes aren't competing for the same resources
	4) So they can be updated independently
		- i.e. you want to switch from Postgres to MySQL?  No reason to take down all of your site to do so!


- Pieces of a large website:

1) DNS round robin
	- What if you have too many requests for one load balancer?
	- at the DNS level, map your URL to multiple IPs
		- Each IP is a separate load balancer machine
2) A cache between a load balancer and your apps
	- if you know it won't change, cache the entire page (HTML and all), instead of just the results of the query!
	- popular technology for this:
		- varnish
		- squid
3) Or you can use a CDN
	- CDN = content delivery network
	- CDN = 3rd party company that will cache your site all over the internet
	- they'll intercept your DNS requests from all over the world
	- they'll check to see if they have the results even before they hit your load balancer!
		- this pushes the cache further from you and closer to the customer


#####################################
# Problem Set 1 - Caching
#####################################

Step 1:
	Add caching to blog
	On the page, display how long ago we ran the query that generated the front page
		i.e. in the footer, print a string like "Queried 159 seconds ago"

Step 2:
	Do the same for the permalinks
	BONUS: make blog link to permalinks

Step 3:
	Make it so /blog/flush flushes the cache, then redirects to /blog
		Note that this should flush not just the blog cache, but the permalink cache too


#####################################
# Lesson 7: Scaling Up
#####################################

Code organization
	There's no correct answer to how to split things up
	Some good divisions:
		main.py
			Starts out as a monolith, broken out over time
			KEEPS URL MAPPING
			Imports all the other bits and pieces
		Handlers
			Could eventually have separate files for every type of handling
		DB models
			ORM - object relational mapping
				Map your objects into DB data
				Steve likes to write his own, doesn't like the pre-made solutions
				Basically abstracts away the SQL?
				We don't have to do this with app engine, it comes with it's own stuff, but often do with other frameworks
			Steve often has a separate file for each entity
				i.e. a file for Post, a file for Art, etc.
				In these files he'd also put all the password hashing stuff, etc.
		Utils
			Just handy things, like make_salt(), make_secure_val(), etc.
			Also date manipulation, string manipulation, etc.
			A list of flat functions that have no dependencies on any other part of the project
				i.e. UTILS SHOULD NOT IMPORT ANYTHING ELSE
				THEY SHOULD BE COMPLETELY INDEPENDENT
					You can use utils with handlers, db stuff, etc., but utils shouldn't use handlers, db stuff, etc.
		Static content
			CSS, JS, images
		Templates

Circular imports/inheritance
	Better not to have this, ideally inheritance should only 

File structure
	/
		main.py
		handlers.py
		Blog.py
		Rot13.py
		/lib
			/DB
				models
			utils.py
		/templates
			base.html
			*** bunch of inheriting templates
		/static

Hosting
	Local
		Run off your own computer
		BUT not always on or accessible
			Internet could go down
		IP may change
			May have to pay extra for static IP
	Co-locate
		Buy space in a datacentre
		Or even have your own datacentre
		Pay for rent, power, bandwidth
		BUT lots of work
			Administer machine
			Install software
			Fix things
			etc.
	Managed hosting
		Old system:
			Rent configured, installed machines from a data centre
		New system:
			Cloud setup
			Big players:
				AWS
				Rackspace
				Linode
				etc.
			Rent machines, often by the hour
			Don't have to think too much about bandwidth, power, etc.
			Generally don't install the OS, but do control OS config
	GAE/Heroku model
		Don't worry about machines, OS, etc.
		Basically zero sys-admin
		BUT difficult customization

Choosing between web frameworks
	webapp2
		Handles:
			HTTP
			Scheduling (handling multiple requests at once)
			URL mapping
			etc.
		Gives direct access to GET/POST
		Direct access to the requests (headers, etc.)
			Can manipulate bits, or the whole header
	Things that frameworks do that are sort of not that important
		Sessions
		Caching
		Forms
		DB-ORM
		*** But what if you need custom behaviour?
			Steve finds this stuff too high level
			Easier/better to just do it yourself
			Not good to be too far away from the request
			You're not going to know what happen when things break
	Templates
		mako, jinja2, etc. are good ones
		Basically, make sure not to put too much code in templates
			Really difficult to maintain
		Stick to using them to generate HTML/CSS, keep the code in the programming language

How Steve works
	Have your browser, editor and terminal all open
		The terminal part is key
		You see all the logs scrolling by, and see all sorts erros that you wouldn't otherwise catch!
			DB queries should be printed to the log too
			You want to see what's being cached, where queries are happening, etc.
			Want to see that there are very few queries running in general

Scaling Reddit

	Started in June 2005
	Steve was the engineer
	Alexis was "everything else" (business, design, etc.)

	First version of Reddit was written in Lisp
		More popular at universities than in the real world
		Handlers were written in Lisp, and it generated the HTML, CSS, JS, etc.
			Lisp is very good at generating source code
		There was no memcache, just an in-memory lookup table

	DB was very simple, just a few tables
		Links
			score, title, url
		Votes
			link_id, dir
		Users
			name, pass
	No comments at the start
	Lots of joins at the start
	Everything was on one machine
		App and DB same machine

	After hiring Aaron:
		Re-wrote in Python
		Split onto 2 machines
			One for App
			One for DB
				Switched to PG
			Split to two machines was ~4x speed improvement!

	At this point, still lots of downtime
		Site crashed A LOT
	At first Steve spent a lot of time simply bringing Reddit back up when it crashed
		You can automate a lot of this!
		A good program is "Supervise" -> restarts your app when it crashes
		Can even have 2 copies of the app running with a load balancer, and Supervise bringing them back up
			Makes it so you really don't have to worry about downtime

	At this point, very few PG backups
		Got SUPER LUCKY
		Machines die, just got really lucky that their PG machine didn't

	DB replication
		Moved to two DBs
		Used a tool called "Sloney" to replicate the db
		Had one app server hitting the two DB machines
		There was one master, one slave
			Then ran into replication lag
			i.e. you'd submit a link, then get re-directed to it, but if you hit the wrong db (where it hadn't been replicated yet), you'd get a 404 error!
		Also had cache lag
			Started a 2nd app server
			Weren't using memcache yet
			Used a library called Spread to keep their two in-memory caches in-sync
			Every time one app server updated its cache, spread had to tell all the app servers about it

	COMMENTS
		First version of comments was just a new table
			Had link ids, contents, author id, etc.
		Every time they wanted to add a feature, it was slow
			Had to worry about db migrations, new indexes, etc.
			Wanted something more flexible
		Moved to "thing db"

	Thing DB
		Designed by Steve
		Instead of having a Link table, with a bunch of columns
			i.e. url, title, date, score
		Have a "thing" table, with the following columns
			thing_id, score, author, date
		Links, comments, subreddits are all "things"
			So you have a thing table, which is essentially references to other tables
		Then you have separate data tables
			Has:
				thing_id, key, value
		Example: representation of a link
			It would have an entry in the thing table
				{
					link_id: 1,
					score: 5,
					author: 25,
					date: 6/11/05
				}
			It would also have a bunch of entries in the data table
				{
					link_id: 1,
					key: url,
					value: *the url*
				}
				{
					link_id: 1,
					key: title,
					value: *the title*
				}
		So any property of a thing that isn't common amongst all things is just a new row in a data table!
			Want to add properties to a table?  Just add more data rows!
			And in your code you can just do things like "if the thing doesn't have this data entry, just use a default value"
		In general, this just makes it really easy to add features without planning much in advance

	Adding memcached
		Should have been using it from the begginging!
		Got all of the state out of the apps, made it way easier to scale app servers
		Let them get rid of Spread (with associated cache lag)

	No sharding in Thing DB
		Should have wrote it in!
		Now really hard to put sharding in, but would have been pretty easy back then

	Framework
		Started out using web.py, which Aaron wrote
			Used handlers, GET/POST, etc.
			webapp2 took a lot from web.py
		Reddit now uses a hacked up version of Pylons, which they made similar to web.py

	Pre-computed cache
		Had a cron job that would compute the "hot" page every minute, then throw it into memcached
		Started doing A LOT of pre-computing (for different sub-reddits, different users, etc.)
		Then started having this whole pre-compute system
			The "absolute truth" dbs replicated to the "pre-compute" dbs
			App servers load up jobs for the pre-compute dbs
				i.e. we want all this data
			The results of these jobs stored in memcached
			App servers basically only get data from memcached
		Makes everything really fast

Interview with Neil
	Neil is responsible for keeping Reddit fast, online and functional
	When Steve left, the infrastructure looked like this:
		CDNs
			Akamai
			Used for logged out users only
				They all see the same content
			Logged in users have custom content, so they can't use CDN
		Load balancer
			HA Proxy
			They now have multiple, then had one
		App servers
			There were 20 when Steve left
			Now 180!
		They use S3 for static content
			S3 is simple storage service
			Destributed file storage thing in the cloud
			Amazon lets you put objects into the buckets
			It's literally just a key/value store of the buckets
			People can ask for files, and get it
			Use it to store HTML, CSS, JS, etc.
			FOR STATIC CONTENT, A USER NEVER HITS HAPROXY, APP SERVERS, ETC.
				So this is just for logged out users
			For awhile they were using nginx for static content
				BUT the one nginx server doing all the static content just couldn't handle it when the static content changed
					i.e. when the static files changed, everyone's cache's became invalid, and everyone needed new static files, which crushed the single nginx machine
	DBs
		When Steve left, they had a few dbs
			One for links/users
			One for votes
			One for comments/subreddits
		Then all of these DBs were replicated
			Used "Londiste"
			They still use it
			Basically, every insert to the main db is replayed to the replicated db
	memcached
		Used A LOT
		Writes went to DB and memcached at the same time
			Avoid replication lag by just accessing memcached
		The pre-compute DBs would throw stuff into memcachedb, which is sort of like memcache with a bit of permanent storage

	Big changes since Steve left
		memcachedb eventually hit a scaling wall
			Just couldn't handle the load
			They replaced it with Casandra
				Automatic sharding accross a ring of servers
				They're using a replication factor of 3
					Every piece of data written 3 times
					You aren't slowed down much by one slow node, and if one node goes down, you've got 2 backups
		zookeeper
			They're now using zookeeper to handle locking
			I don't really get this bit
			It can also push data to App Servers
				Compared to, say, memcache, which can only serve requests from app servers
			So if your configuration changes, zookeeper can tell your apps
		memcache injection
			memcached client library has the ability to notice that a node has gone down
			At that point it'll treat the ring as if it has one less node

	mapreduce
		A programming technique for doing batch across huge amounts of data
		Two functions:
			map
				Given this list of things, apply this function to it
			reduce
				Given these two things, apply this function to it and reduce it into one thing
		Reddit is/will be using Hadoop, with a language called pig
			Makes it easy to distribute the mappers and reducers across nodes
			Will be using Amazon's elastic map reduce
				Hosted Hadoop

	new vs. old content
		They were handling regularly accessed data just fine
		But what if someone wants to check out a really old 500 comment thread?
			That's 500 disk hits!
		A big issue here is Google
			They actually had to build a whole separate infrastructure just for Google!
			It's read-only, and it's how Google indexes them
			They just have very different behaviour from normal users

	Locking
		With Cassandra, whenever you vote on a link in a specific subreddit, it has to lock on that whole subreddit
		Basically, they're trying to get rid of locking as much as possible, in general

Growing Reddit from a social point of view
	At the beginning, fake content!
		Steve and Alexis submitted a bunch of fake content, from fake users!
			They had a system to make this easy
		This did two things:
			1) Set the tone
				They were submitting good, interesting stuff
			2) Made the site feel alive
				Want a bumping site!
		They had to do this for the first few months
	There were no comments for the first few months
		This is now one of the most important parts!
		But they didn't realize that until later
	There was no categorization
		i.e. tags, etc.
		This was good, users could just show up and submit content, it was easy
	No emails
		If you want members, and want submissions, why ad barriers?
	No censorship
		Unless it was overtly racist, they didn't censor
		Created a real sense of community
	Spam/cheating prevention
		What do spammers want?
			Very often they want links to their pages, for SEO
			One thing to fight this, is to just add this by default to all links:
				<a rel="nofollow" href=...
			They take this away for popular posts, but the unpopular spam posts contribute nothing to SEO
		Spam is almost always automated
			You can notice things
				A bunch of accounts all using the same password
				Users submitting content, then commenting on their own content
				Submitting content way too quickly for a human
		Don't let a spammer know when they're caught!
			Make it so that the spammer sees their own stuff, but nobody else does

Next steps
	Learn front end technologies
		CSS
		JavaScript
			As well as AJAX
				"Asychronous JavaScript"
				Making HTTP requests, in the background, to your web server, to update the page dynamically
					i.e. voting on Reddit, you send the vote to the server, but don't get a new page

Scaling Udacity/app engine
	Nice things app engine does
		They provide great infrastructure
			caching
			highly replicated datastore
			force you to address consistency
				does a name have to be updated everywhere, or can it wait a bit?
			queueing
				very powerful/smooth/reliable
				let's you really focus on tasks
			logging infrastructure works really well
		Version handling
			You can upload a completely different code base, against the same data stores and services
			Makes A/B testing really easy
				Test new features only on a small set of users, see if it's successful
			Also makes it easy to have an admin site
		Autoscaling
			Probably the best feature off app enginge
			Super easy to scale your db, memcache, etc.
			They can handle traffic spikes without thinking about it
		It's clear that app engine was designed by people who had gone through the painful process of scaling
			For example, queueing can get really complex
				It's just done in a really simple way in app engine
		Deployment is very easy
	Downsides of app engine
		Migrating off app engine is really hard
		Sometimes there are failures
			A query that normally works, ocassionally doesn't work
				Have to do things like "if a query fails, try again up to 3 times before sending an error back to the user"
		There's a 10 minute limit for tasks running on the back end
		You can't have C modules
			Which are popular in Python systems
		Better SSL certificate support
			Especially on custom domains
			But they're fixing this relatively soon?
		Database limitations
			All queries have a limit of 1000 records!
			Backup/restore is very awkward
				Hard to backup all your data on a nightly basis
				Also expensive to do it
			Not a very good data viewer
				There's a data viewer on the dasboard, but you can't do standard SQL queries


#####################################
# Final exam: Build a Wiki
#####################################

A Wiki is just a website where any page can be edited
If you type in a url that doesn't exist:
		/stuff
	You should be re-directed to an edit page:
		/_edit/stuff
	Where you can edit the HTML
If you type in a url that does exist, you should be taken to the page, and there should be an edit button
There should also be user accounts
	When not logged in you can see pages, but not edit them
	So still need signup, new user pages
	Signup should be at:
		/signup

Our routing should look something like this:

PAGE_RE = r'(/(?:[a-zA-Z0-9_-]+/?)*)'
app = webapp2.WSGIApplication(
	[
		('/signup', Signup),
		('/login', Login),
		('/logout', Logout),
		('/_edit' + PAGE_RE, EditPage),
		(PAGE_RE, WikiPage)
	],
	debug=DEBUG
)
